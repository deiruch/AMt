{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.dummies.com/programming/python/plotting-a-sound-file-in-ipython/\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile as wav\n",
    "from scipy.fftpack import fft\n",
    "import numpy as np\n",
    "from gurobipy import *\n",
    "from IPython.display import Audio\n",
    "import os\n",
    "import glob\n",
    "import untangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for transforming a signal with fourier\n",
    "def fourier_trans(data, rate, begin_time, end_time): \n",
    "    # initialising variables\n",
    "    tp_count = len(data)\n",
    "    values = np.arange(int(tp_count/2))\n",
    "    time_period = tp_count/rate\n",
    "    frequencies = values/time_period\n",
    "    \n",
    "    #at what intervals time points are sampled\n",
    "    sampling_interval = 1/rate;\n",
    "    \n",
    "    #time points\n",
    "    time = np.arange(begin_time, end_time, sampling_interval);\n",
    "    \n",
    "    #Frequency domain representation\n",
    "    fourier_transform = fft(data)/tp_count #normalized the amplitude\n",
    "    fourier_transform = fourier_transform[range(int(len(data)/2))] #exclude sampling frequency   \n",
    "    return frequencies, abs(fourier_transform)\n",
    "\n",
    "# TODO: Funktion überarbeiten damit man es auch versteht!\n",
    "def new_fft(data, rate):\n",
    "    N = len(data)\n",
    "\n",
    "    # sample spacing\n",
    "    T = 1.0 / rate\n",
    "    x = np.linspace(0.0, N*T, N)\n",
    "\n",
    "    yf = fft(data)\n",
    "    freq = np.linspace(0.0, 1.0/(2.0*T), N//2)\n",
    "    ampl = 2.0/N * np.abs(yf[0:N//2])\n",
    "    return freq, ampl\n",
    "\n",
    "# Frequency domain representation\n",
    "def plot_freq_domain(freq, fourier, name):\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.plot(freq, fourier)\n",
    "    plt.xlabel('Frequency in Hz')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.xlim(0, 1400)\n",
    "    plt.title(name)\n",
    "    plt.show()\n",
    "\n",
    "# TODO: Warnung herausgeben wenn bei der Teilung der Samplerate eine Fliesskommazahl entsteht\n",
    "def easy_downsampling(data, rate, sampl_fac):\n",
    "    ds_data = []\n",
    "    for i in range(len(data)):\n",
    "        if (i%sampl_fac == 0):\n",
    "            ds_data.append(data[i])\n",
    "    ds_rate = int(rate/sampl_fac)\n",
    "    return ds_data, ds_rate\n",
    "\n",
    "#ToDo: startwert von 0 nicht möglich überarbeiten!!\n",
    "def snip_wav(data, rate, start_sec, end_sec):\n",
    "    start_point = int((rate * start_sec)-1)\n",
    "    end_point = int((rate * end_sec)-1)\n",
    "    #print('start_point:', start_point)\n",
    "    #print('end_point:', end_point)\n",
    "    snip_data = data[start_point:end_point]\n",
    "    #print(snip_data)  \n",
    "    return snip_data, rate\n",
    "\n",
    "def metric(target_v, approx_v):\n",
    "    norm_factor = np.linalg.norm(approx_v)\n",
    "    if (norm_factor != 0):\n",
    "        norm_v = approx_v/norm_factor\n",
    "        diff = target_v - norm_v\n",
    "        diff_sum = np.sum(np.abs(diff))\n",
    "        return diff_sum\n",
    "    else:\n",
    "        print('Der Vektor kann nicht normalisiert werden.')\n",
    "        return approx_v "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Set audio snippets and sample compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_sec = 1\n",
    "end_sec = 2.5\n",
    "sampl_fac = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictonary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NEW\n",
    "## Read WAV File\n",
    "#\n",
    "#audio_files = []\n",
    "#path_wav = \"audiofile\"\n",
    "#path_xml = \"annotation\"\n",
    "#\n",
    "## Init dict (combining same pitches into one)\n",
    "#ref_note = {}\n",
    "#note = 0\n",
    "#\n",
    "#for filename in sorted(glob.glob(os.path.join(path_xml, '*.xml'))):\n",
    "#    \n",
    "#    # Read data from xml\n",
    "#    obj = untangle.parse(filename)\n",
    "#    audiofile = obj.instrumentRecording.globalParameter.audioFileName.cdata\n",
    "#    pitch = obj.instrumentRecording.transcription.event.pitch.cdata\n",
    "#    #onsetSec = obj.instrumentRecording.transcription.event.onsetSec.cdata\n",
    "#    #offsetSec = obj.instrumentRecording.transcription.event.offsetSec.cdata\n",
    "#    fretNumber = obj.instrumentRecording.transcription.event.fretNumber.cdata\n",
    "#    stringNumber = obj.instrumentRecording.transcription.event.stringNumber.cdata\n",
    "#    \n",
    "#    # Read wav\n",
    "#    wav_file = path_wav + '/' + audiofile\n",
    "#    rate, data = wav.read(wav_file)\n",
    "#    \n",
    "#    # Snip and downsampling audio-file\n",
    "#    data, rate = snip_wav(data, rate, start_sec, end_sec)\n",
    "#    data, rate = easy_downsampling(data, rate, sampl_fac)\n",
    "#    \n",
    "#    # Calc FFT\n",
    "#    #freq, fourier = fourier_trans(data, rate, float(onsetSec), float(offsetSec))\n",
    "#    #freq, fourier = fourier_trans(data, rate, 0, 2.5)\n",
    "#    #freq, fourier = fourier_trans(data, rate, 0, end_sec-start_sec)\n",
    "#    freq, fourier = new_fft(data, rate)\n",
    "#    \n",
    "#    # Update Dict\n",
    "#    #ref_note[filename] = {\n",
    "#    ref_note[note] = {\n",
    "#        \"pitch\": int(pitch),\n",
    "#        \"fret\": int(fretNumber),\n",
    "#        \"string\": int(stringNumber),\n",
    "#        \"rate\": int(rate),\n",
    "#        \"data\": data,\n",
    "#        #\"onset\": float(onsetSec), \n",
    "#        #\"offset\": float(offsetSec), \n",
    "#        \"freq\": freq,\n",
    "#        \"fourier\": fourier,\n",
    "#    }\n",
    "#    note+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as et\n",
    " \n",
    "def parse_XML(xml_file, df_cols):\n",
    "    \"\"\"Parse the input XML file and store the result in a pandas\n",
    "    DataFrame with the given columns.\n",
    "    \n",
    "    The first element of df_cols is supposed to be the identifier\n",
    "    variable, which is an attribute of each node element in the\n",
    "    XML data; other features will be parsed from the text content\n",
    "    of each sub-element.\n",
    "    \"\"\"\n",
    "   \n",
    "    xtree = et.parse(xml_file)\n",
    "    xroot = xtree.getroot()\n",
    "    rows = []\n",
    "   \n",
    "    for node in xroot[1]:\n",
    "        print('node:', node)\n",
    "        res = []\n",
    "        res.append(node.attrib.get(df_cols[0]))\n",
    "        print('res:',res)\n",
    "        for el in df_cols[1:]:\n",
    "            print('elem:', el)\n",
    "            if node is not None and node.find(el) is not None:\n",
    "                res.append(node.find(el).text)\n",
    "            else:\n",
    "                res.append(None)\n",
    "        rows.append({df_cols[i]: res[i]\n",
    "                     for i, _ in enumerate(df_cols)})\n",
    "   \n",
    "    out_df = pd.DataFrame(rows, columns=df_cols)\n",
    "       \n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_file = 'annotation/G53-40100-1111-00001.xml'\n",
    "df_cols = ['pitch', 'fret']\n",
    "parse_XML(xml_file, df_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtree = et.parse(xml_file)\n",
    "xroot = xtree.getroot()\n",
    "\n",
    "for event in xroot[1]:\n",
    "    pitch = event.find('pitch').text\n",
    "    onset = event.find('onsetSec').text\n",
    "    print(pitch, onset)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xroot.attrib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment with df and list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read WAV File\n",
    "\n",
    "audio_files = []\n",
    "path_wav = \"audiofile\"\n",
    "path_xml = \"annotation\"\n",
    "\n",
    "# Init dict\n",
    "ref_note = {}\n",
    "note = 0\n",
    "l_r_n = []\n",
    "\n",
    "for filename in sorted(glob.glob(os.path.join(path_xml, '*.xml'))):\n",
    "    \n",
    "    # Read data from xml\n",
    "    obj = untangle.parse(filename)\n",
    "    audiofile = obj.instrumentRecording.globalParameter.audioFileName.cdata\n",
    "    pitch = obj.instrumentRecording.transcription.event.pitch.cdata\n",
    "    #onsetSec = obj.instrumentRecording.transcription.event.onsetSec.cdata\n",
    "    #offsetSec = obj.instrumentRecording.transcription.event.offsetSec.cdata\n",
    "    fretNumber = obj.instrumentRecording.transcription.event.fretNumber.cdata\n",
    "    stringNumber = obj.instrumentRecording.transcription.event.stringNumber.cdata\n",
    "    \n",
    "    # Read wav\n",
    "    wav_file = path_wav + '/' + audiofile\n",
    "    rate, data = wav.read(wav_file)\n",
    "    \n",
    "    # Snip and downsampling audio-file\n",
    "    data, rate = snip_wav(data, rate, start_sec, end_sec)\n",
    "    data, rate = easy_downsampling(data, rate, sampl_fac)\n",
    "    \n",
    "    # Calc FFT\n",
    "    #freq, fourier = fourier_trans(data, rate, float(onsetSec), float(offsetSec))\n",
    "    #freq, fourier = fourier_trans(data, rate, 0, 2.5)\n",
    "    #freq, fourier = fourier_trans(data, rate, 0, end_sec-start_sec)\n",
    "    freq, fourier = new_fft(data, rate)\n",
    "    \n",
    "    # Update Dict\n",
    "    #ref_note[filename] = {\n",
    "    ref_note = {\n",
    "        \"pitch\": int(pitch),\n",
    "        \"fret\": int(fretNumber),\n",
    "        \"string\": int(stringNumber),\n",
    "        \"rate\": int(rate),\n",
    "        \"data\": data,\n",
    "        #\"onset\": float(onsetSec), \n",
    "        #\"offset\": float(offsetSec), \n",
    "        \"freq\": freq,\n",
    "        \"fourier\": fourier,\n",
    "    }\n",
    "    l_r_n.append(ref_note)\n",
    "    #note+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_note = [ref_note]\n",
    "#list_note\n",
    "l_r_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_ = pd.DataFrame(l_r_n)\n",
    "df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['pitch', 'freq', 'fourier']\n",
    "df__ = df_[columns]\n",
    "df__.loc[df__['pitch'] == 45]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df__.groupby(['pitch']).agg(\n",
    "#mean_freq = pd.NamedAgg(column='freq', aggfunc=sum),\n",
    "#mean_fourier = pd.NamedAgg(column='fourier', aggfunc=sum))\n",
    "grouped_df = df__.groupby(['pitch']).sum().reset_index()\n",
    "grouped_df.loc[grouped_df['pitch'] == 45]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_cols = df_.columns.tolist()\n",
    "print(index_cols)\n",
    "index_cols.remove('pitch')\n",
    "print(index_cols)\n",
    "\n",
    "df__ = df_.groupby(index_cols)\n",
    "df__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum fourier-values \n",
    "combi = [(a+b)/2 for a, b in zip(note_dict[5]['fourier'], note_dict[6]['fourier'])]\n",
    "print(combi)\n",
    "len(combi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tone = 5\n",
    "plot_freq_domain(note_dict[tone]['freq'], combi,'Pitch: %g' %ref_note[tone]['pitch'])\n",
    "print('data:', len(ref_note[tone]['data']))\n",
    "print('rate:', ref_note[tone]['rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tone = 5\n",
    "plot_freq_domain(ref_note[tone]['freq'], ref_note[tone]['fourier'],'Pitch: %g' %ref_note[tone]['pitch'])\n",
    "print('data:', len(ref_note[tone]['data']))\n",
    "print('rate:', ref_note[tone]['rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tone = 6\n",
    "plot_freq_domain(ref_note[tone]['freq'], ref_note[tone]['fourier'], 'Pitch: %g' %ref_note[tone]['pitch'])\n",
    "print('data:', len(ref_note[tone]['data']))\n",
    "print('rate:', ref_note[tone]['rate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read audiofile for approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chords\n",
    "#rate_chord, data_chord = wav.read('audiofile/1-E1-Major 00.wav')\n",
    "#rate_chord, data_chord = wav.read('audiofile/1-E1-Major 01.wav')\n",
    "\n",
    "# Single note\n",
    "#rate_chord, data_chord = wav.read('audiofile/G53-65601-1111-00067.wav')\n",
    "rate_chord, data_chord = wav.read('audiofile/G53-40100-1111-00001.wav')\n",
    "\n",
    "# Single note played on another guitar\n",
    "#rate_chord, data_chord = wav.read('audiofile/G53-42102-1111-237.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mischsignal mischsignal\n",
    "data_20, rate_20 = snip_wav(data_chord, rate_chord, start_sec, end_sec)\n",
    "data_ds, rate_ds = easy_downsampling(data_20, rate_20, sampl_fac)\n",
    "freq, mischsignal = new_fft(data_ds, rate_ds)\n",
    "#freq, mischsignal = new_fft(data_chord, rate_chord)\n",
    "\n",
    "plot_freq_domain(freq, mischsignal, 'Mischsignal')\n",
    "#print('data:', len(data_ds))\n",
    "#print('rate:', rate_ds)\n",
    "print('Länge Mischsignal: ', len(mischsignal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gurobi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Model\n",
    "m = Model('AMt')\n",
    "\n",
    "lambs = []\n",
    "for lamb in range(len(ref_note)):\n",
    "    lambs.append(m.addVar(lb = 0, vtype = GRB.CONTINUOUS, name = 'lamb_' + str(lamb)))\n",
    "m.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "%%time\n",
    "#Optimize Signal\n",
    "\n",
    "deviation = 0\n",
    "approxi_sgn = 0\n",
    " \n",
    "for sgn in range(len(mischsignal)):\n",
    "#for sgn in range(100):\n",
    "    for lamb in range(len(lambs)):\n",
    "        approxi_sgn += lambs[lamb] * ref_note[lamb]['fourier'][sgn]\n",
    "        \n",
    "    deviation += ((mischsignal[sgn] - approxi_sgn)*(mischsignal[sgn] - approxi_sgn))\n",
    "    # deviation wird ausmultipliziert stattdessen die für 'mischsignal[sgn] - approxi_sgn'\n",
    "    # eine Gurobi-Variable (m.addVar  inkl. constr.) verwenden\n",
    "    # Überprüfen ob der Betrag der Differenz besser geeignet ist?\n",
    "print('Deviation is calculated.')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Schlaufen vertauscht\n",
    "deviation = 0\n",
    "approxi_sgn = 0\n",
    "\n",
    "for lamb in range(len(lambs)):\n",
    "    la = lambs[lamb]\n",
    "    print('la:', la)\n",
    "    note = ref_note[lamb]['fourier']\n",
    "    \n",
    "    for sgn in range(len(mischsignal)):\n",
    "        approxi_sgn = la * note[sgn]\n",
    "        mi = mischsignal[sgn]\n",
    "        deviation += ((mi - approxi_sgn)*(mi - approxi_sgn))\n",
    "print('Deviation is calculated.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "m.setObjective(deviation, GRB.MINIMIZE)\n",
    "m.optimize()\n",
    "\n",
    "approx_v = []\n",
    "\n",
    "for v in m.getVars():\n",
    "    print('%s: %g' % (v.varName, v.x))\n",
    "    approx_v.append(v.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrik berechnen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_v = np.zeros(78,dtype=int)\n",
    "target_v[0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric(target_v, approx_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_xml = \"recordings/annotation\"\n",
    " \n",
    "audio_input = {}\n",
    " \n",
    "for filename in glob.glob(os.path.join(path_xml, '*.xml')):\n",
    "    obj = untangle.parse(filename)\n",
    "    audiofile = obj.instrumentRecording.globalParameter.audioFileName.cdata\n",
    "    event = obj.instrumentRecording.transcription.event\n",
    "   \n",
    "    i=0\n",
    "    event_dict = {}\n",
    "   \n",
    "    for e in event:\n",
    "        pitch = e.pitch.cdata\n",
    "        onsetSec = e.onsetSec.cdata\n",
    "        event_dict['event_' + str(i)] = {\n",
    "            \"pitch\": int(pitch),\n",
    "            \"onset\": float(onsetSec)\n",
    "        }\n",
    "        i+=1\n",
    "   \n",
    "    audio_input[audiofile] = event_dict\n",
    "audio_input"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
